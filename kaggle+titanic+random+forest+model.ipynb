{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "#### import our desired libraries\n",
    "#################################################\n",
    "\n",
    "# pandas\n",
    "import pandas as pd\n",
    "from pandas import Series,DataFrame\n",
    "\n",
    "# numpy, matplotlib, seaborn, sklearn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# setup a style to view ipython notebook graphs\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "#### import the data\n",
    "test   = pd.read_csv('../input/test.csv')\n",
    "train    = pd.read_csv('../input/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################################################\n",
    "#### feature engineering \n",
    "#################################################\n",
    "\n",
    "\n",
    "###train['Ticket_group'] = np.where(train['Ticket'].str.isdigit(), train['Ticket'].astype(str).str[0], train['Ticket'].str[:1])\n",
    "train['Ticket_length'] = train['Ticket'].apply(lambda x: len(x))\n",
    "###test['Ticket_group'] = np.where(test['Ticket'].str.isdigit(), test['Ticket'].astype(str).str[0], test['Ticket'].str[:1])\n",
    "test['Ticket_length'] = test['Ticket'].apply(lambda x: len(x))\n",
    "\n",
    "train[\"NameLength\"] = train[\"Name\"].apply(lambda x: len(x))\n",
    "test[\"NameLength\"] = test[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "\n",
    "\n",
    "########## this counts the number of spaces in the Name column\n",
    "import re\n",
    "\n",
    "at = re.compile(r\" \", re.I)\n",
    "def count_spaces(string):\n",
    "    count = 0\n",
    "    for i in at.finditer(string):\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "train[\"spaces_in_name\"] = train[\"Name\"].map(count_spaces)\n",
    "test[\"spaces_in_name\"] = test[\"Name\"].map(count_spaces)\n",
    "\n",
    "\n",
    "#########################################################\n",
    "##### This function returns the title from a name\n",
    "#########################################################\n",
    "\n",
    "def title(name):\n",
    "# Search for a title using a regular expression. Titles are made of capital and lowercase letters ending with a period.\n",
    "    find_title = re.search(' ([A-Za-z]+)\\.', name)\n",
    "# Extract and return the title If it exists. \n",
    "    if find_title:\n",
    "        return find_title.group(1)\n",
    "    return \"\"\n",
    "\n",
    "train[\"Title\"] = train[\"Name\"].apply(title)\n",
    "test[\"Title\"] = test[\"Name\"].apply(title)\n",
    "\n",
    "##### making some edits for the very small title groups \n",
    "train['Title'] = train['Title'].replace(['Don', 'Capt', 'Major', 'Sir', 'Rev', 'Col'], 'Sir')\n",
    "train['Title'] = train['Title'].replace(['Dona', 'Lady', 'the Countess', 'Jonkheer', 'Mme', 'Mlle', 'Countess'], 'Lady')\n",
    "train['Title'] = train['Title'].replace(['Ms'], 'Miss')\n",
    "\n",
    "test['Title'] = test['Title'].replace(['Don', 'Capt', 'Major', 'Sir', 'Rev', 'Col'], 'Sir')\n",
    "test['Title'] = test['Title'].replace(['Dona', 'Lady', 'the Countess', 'Jonkheer', 'Mme', 'Mlle', 'Countess'], 'Lady')\n",
    "test['Title'] = test['Title'].replace(['Ms'], 'Miss')\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "##### add some additional interesting vars\n",
    "#########################################################\n",
    "\n",
    "train['Cabin_first_ltr'] = np.where(train['Cabin'].isnull(), 'Null', 'Not Null')\n",
    "##train['Parch_grouped'] = np.where(train['Parch'] > 0, '1', '0')\n",
    "train['FamilySize'] = train['SibSp'] + train['Parch']\n",
    "train['withfamily'] = np.where(train['FamilySize'] > 0, 1, 0)\n",
    "train['Female'] = np.where(train['Sex'] == 'female', 1, 0)\n",
    "\n",
    "train['miss'] = np.where(train['Name'].str.contains(\"Miss. \"), 1, 0)\n",
    "train['mrs'] = np.where(train['Name'].str.contains(\"Mrs. \"), 1, 0)\n",
    "\n",
    "\n",
    "\n",
    "#########################################################\n",
    "##### Group up the ticket variable\n",
    "#########################################################\n",
    "train[\"Ticket_grp\"] = np.where(train['Ticket'].str.isdigit(), train['Ticket'].astype(str).str[0], train[\"Ticket\"].str.split(' ').str.get(0))\n",
    "test[\"Ticket_grp\"] = np.where(test['Ticket'].str.isdigit(), test['Ticket'].astype(str).str[0], test[\"Ticket\"].str.split(' ').str.get(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########################################################\n",
    "#### bucket the continuous age variable into categories\n",
    "###########################################################\n",
    "\n",
    "train['Age_grouped'], bins = pd.qcut(train['Age'], 10, retbins = True)\n",
    "test['Age_grouped'] = pd.cut(test[\"Age\"], bins=bins, include_lowest=True)\n",
    "\n",
    "train['Fare_grouped'], Fare_bins = pd.qcut(train['Fare'], 4, retbins = True)\n",
    "test['Fare_grouped'] = pd.cut(test[\"Fare\"], bins=Fare_bins, include_lowest=True)\n",
    "\n",
    "\n",
    "###### note that some of the age values were missing and thus the age_grouped is missing too\n",
    "#train['Age_grouped'][train['Age'] == train['Age'].median()].unique()\n",
    "\n",
    "train['Age_grouped'] = np.where(train['Age_grouped'].isnull(), \"(25, 28]\", train['Age_grouped'])\n",
    "test['Age_grouped'] = np.where(test['Age_grouped'].isnull(), \"(25, 28]\", test['Age_grouped'])\n",
    "\n",
    "train['Fare_grouped'] = np.where(train['Fare_grouped'].isnull(), \"(7.91, 14.454]\", train['Fare_grouped'])\n",
    "test['Fare_grouped'] = np.where(test['Fare_grouped'].isnull(), \"(7.91, 14.454]\", test['Fare_grouped'])\n",
    "\n",
    "##train['Fare_grouped'][train['Fare'] == train['Fare'].median()].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### what's the distribution of age? \n",
    "#sns.violinplot(data=train['Age'])\n",
    "\n",
    "#sns.violinplot(data = train['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## to run a random forest we need to make sure the dataset doens't contain any missing values.\n",
    "### does it contain missing values\n",
    "if train.isnull().values.any() == True:\n",
    "    print(\"there are some missing values\")\n",
    "else: \n",
    "    print(\"there are no missing values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Make adjustments to the test dataset to match the train dataset\n",
    "\n",
    "test['Cabin_first_ltr'] = np.where(test['Cabin'].isnull(), 'Null', 'Not Null')\n",
    "test['FamilySize'] = test['SibSp'] + test['Parch']\n",
    "test['withfamily'] = np.where(test['FamilySize'] > 0, 1, 0)\n",
    "test['Female'] = np.where(test['Sex'] == 'female', 1, 0)\n",
    "\n",
    "test['miss'] = np.where(test['Name'].str.contains(\"Miss. \"), 1, 0)\n",
    "test['mrs'] = np.where(test['Name'].str.contains(\"Mrs. \"), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### this removes the missing values\n",
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].median() for c in X],\n",
    "            index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n",
    "    \n",
    "\n",
    "\n",
    "### this will transfer the categorical variables to floats for the algo\n",
    "def do_treatment(df):\n",
    "    for col in df:\n",
    "        if df[col].dtype == np.dtype('O'):\n",
    "            df[col] = df[col].apply(lambda x : hash(str(x)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train_imputed = DataFrameImputer().fit_transform(train)\n",
    "test_imputed = DataFrameImputer().fit_transform(test)\n",
    "\n",
    "do_treatment(train_imputed)\n",
    "do_treatment(test_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## Creating the random forest model \n",
    "# Create the random forest object which will include all the parameters\n",
    "# for the fit\n",
    "forest = RandomForestClassifier(n_estimators = 200, max_features = 'sqrt',\n",
    "                             max_depth = None, verbose = 1, n_jobs = -1)\n",
    "\n",
    "# Fit the training data to the Survived labels and create the decision trees\n",
    "#train_independent_vars = train_imputed.drop(['Survived'], axis = 1)\n",
    "train_independent_vars = train_imputed[['Ticket_length', 'Title', 'NameLength', 'Pclass', 'Female', 'Age_grouped', 'Ticket_grp', 'Fare_grouped', 'Cabin_first_ltr', 'spaces_in_name']]\n",
    "train_independent_vars = train_independent_vars\n",
    "##, 'Embarked', 'withfamily'\n",
    "train_dependent_vars = train_imputed['Survived']\n",
    "\n",
    "forest = forest.fit(train_independent_vars, train_dependent_vars)\n",
    "\n",
    "# Take the same decision trees and run it on the test data\n",
    "output = forest.predict(test_imputed[['Ticket_length', 'Title', 'NameLength', 'Pclass', 'Female', 'Age_grouped', 'Ticket_grp', 'Fare_grouped', 'Cabin_first_ltr', 'spaces_in_name']])\n",
    "\n",
    "### combine the passengerid with the prediction\n",
    "output_df = pd.DataFrame(test_imputed.PassengerId).join(pd.DataFrame(output))\n",
    "output_df.columns = ['PassengerId', 'Survived']\n",
    "#### create the final output dataframe\n",
    "final_output = DataFrame(columns=['PassengerId', 'Survived'])\n",
    "final_output = final_output.append(output_df[['PassengerId', 'Survived']])\n",
    "\n",
    "#### convert from string to ints \n",
    "final_output['PassengerId'] = final_output['PassengerId'].astype(int)\n",
    "final_output['Survived'] = final_output['Survived'].astype(int)\n",
    "\n",
    "#### convert to csv\n",
    "final_output.to_csv('output.csv', index = False, header = ['PassengerId', 'Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "importances = forest.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in indices:\n",
    "    print(train_independent_vars.columns[f], importances[f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
